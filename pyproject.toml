[project]
name = "localbricks"
dynamic = ["version"]
description = "Write code that works the same locally and in Databricks"
readme = "README.md"
authors = [
    { name = "Anders Poirel", email = "contact@anderspoirel.net" }
]
requires-python = ">=3.10"
dependencies = [
    "databricks-sdk>=0.36",
]

[project.optional-dependencies]
connect = ["databricks-connect>=13"]

[dependency-groups]
dev = [
    "mypy>=1.16.0",
    # we want regular Spark for unit tests, but in we don't want to install when
    # running on a Databricks cluster since it would interfere with the runtime's Spark.
    "pyspark[connect]==3.5.5",
    "pytest>=8.4.0",
    "ruff>=0.11.13",
    # pyspark.sql.connect used 'distutils' for a Pandas version check. In Python 3.12+
    # where distutils is removed from the standard library, use the version provided
    # by 'setuptools' instead. TODO: remove this once this is fixed in Spark release.
    'setuptools; python_version >= "3.12"',
]

[build-system]
requires = ["flit_core>=3.2"]
build-backend = "flit_core.buildapi"
